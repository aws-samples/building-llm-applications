{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08b1c701-00a6-4ded-9853-26c6ffab1d65",
   "metadata": {},
   "source": [
    "# Generate images from logos with Stable Diffusion fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5fa45f-8aad-443b-b182-d0d1237f2e53",
   "metadata": {},
   "source": [
    "---\n",
    "Imagine having an application that easily generates an image on how your product logo can be put on the wall or on banners, and see how they look like, probably for an ideation and visualization of a PoC. While Stable Diffusion model can generate images, it may not know how to draw your logo / icon yet. So in this lab, we will see how we can fine-tune a Stable Diffusion model for this purpose. We will use some image samples and their captions. Please look at the training_images folder.\n",
    "\n",
    "In this demo notebook, we demonstrate how to use the JumpStart APIs to fine-tune the Stable Diffusion model. The training script is based on Dreambooth, with some modification to allow multiple objects training and to log the loss into CloudWatch metrics so that you can plot the loss vs time.\n",
    "\n",
    "Note: To run this notebook, you would need the **`Data Science 3.0`** kernel in SageMaker Studio. For performing local inference (step 4), a [GPU-attached instance type](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-instance-types.html#notebooks-resources-gpu) such as `ml.g4dn.xlarge`, `ml.g5.xlarge`, `ml.g4dn.2xlarge` or `ml.g5.2xlarge` is required. Otherwise, the notebook should work with most SageMaker Studio instance types.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ace8f4-379d-4c83-bdbd-bec2cea84208",
   "metadata": {},
   "source": [
    "0. [Set Up](#set-up)\n",
    "\n",
    "1. [Deploy and test the SageMaker JumpStart model](#section-1)\n",
    "\n",
    "2. [Fine-tune the pre-trained model on a custom dataset](#section-2)\n",
    "\n",
    "3. [Further tuning the model with hyperparameter optimization](#section-3)\n",
    "\n",
    "4. [Test locally (only if using GPU-attached instance for kernel)](#section-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c52271-e87c-4f7b-bddf-3936968aafd1",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6fcf2-cb88-41f7-93c9-b6bffc85f521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import botocore\n",
    "import sagemaker, boto3, json\n",
    "import matplotlib.pyplot as plt\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.utils import unique_name_from_base\n",
    "from sagemaker import get_execution_role\n",
    "import os\n",
    "import time\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "training_bucket = sess.default_bucket()\n",
    "\n",
    "# If uploading to a different folder, change this variable.\n",
    "local_training_dataset_folder = \"training_images\"\n",
    "if not os.path.exists(local_training_dataset_folder):\n",
    "    os.mkdir(local_training_dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50945563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import custom functions from utils.py\n",
    "from utils import query, parse_response, query_endpoint_with_json_payload, parse_response_multiple_images, display_img_and_prompt, image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178be8b-3781-4947-a76b-192960f28831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instance prompt is fed into the training script via dataset_info.json present in the training folder. Here, we write that file.\n",
    "import os\n",
    "import json\n",
    "instance_prompt = \"AWS Lambda\"\n",
    "with open(os.path.join(local_training_dataset_folder, \"dataset_info.json\"), \"w\") as f:\n",
    "    f.write(json.dumps({\"instance_prompt\": instance_prompt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18866c3f-5e26-4da2-8deb-1bb71b1477c7",
   "metadata": {},
   "source": [
    "Let's first take a look at the data. The caption is also important. For now we are using images of the `AWS Lambda` icon for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8fe3f0-64b8-4272-95a2-361170fddcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_paths = os.listdir(local_training_dataset_folder)\n",
    "num_images = len(image_paths)-1\n",
    "rows, cols = (int(num_images/4)+1,4)\n",
    "images = []\n",
    "for path in image_paths:\n",
    "    if path == \".ipynb_checkpoints\" or path == \"dataset_info.json\": \n",
    "        continue\n",
    "    image_path = f\"{local_training_dataset_folder}/{path}\"\n",
    "    images.append(Image.open(image_path))\n",
    "image_grid(images, rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861654b-7ac4-458a-b8fb-b87d124d4a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = unique_name_from_base(\"logos-to-images\", max_length=32)\n",
    "run_name = str(time.ctime()).replace(\" \",\"-\").replace(\":\",\"-\")\n",
    "project_s3_path = f\"s3://{training_bucket}/{experiment_name}/{run_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbdd3a-faeb-4ccd-9260-26f006095ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_s3_path = f\"{project_s3_path}/dataset/\"\n",
    "\n",
    "!aws s3 cp --recursive $local_training_dataset_folder $dataset_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85acf76d-e17c-458f-80d5-3ae82c289334",
   "metadata": {},
   "source": [
    "## <a id=\"section-1\">1. Deploy and test the SageMaker JumpStart model<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32551535-c078-4bf1-a626-e25ef4d23da0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "\n",
    "# Retrieves all Text-to-Image generation models.\n",
    "filter_value = \"task == txt2img\"\n",
    "txt2img_models = list_jumpstart_models(filter=filter_value)\n",
    "\n",
    "# display the model-ids in a dropdown to select a model for inference.\n",
    "model_dropdown = Dropdown(\n",
    "    options=txt2img_models,\n",
    "    value=\"model-txt2img-stabilityai-stable-diffusion-v2-1-base\",\n",
    "    description=\"Select a model\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")\n",
    "display(model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bfee67-fad9-4eb3-8382-4691a2b45c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "inference_instance_type = \"ml.g5.2xlarge\"\n",
    "model_id = model_dropdown.value\n",
    "endpoint_name = unique_name_from_base(f\"jumpstart-{model_id}\")\n",
    "\n",
    "jumpstart_model = JumpStartModel(model_id=model_id)\n",
    "predictor = jumpstart_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049057aa-9376-4bec-b659-ff7bcdf35872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple text input\n",
    "prompt = \"AWS Lambda on a rock, in a dream landscape, cinematic composition, futuristic, in the mountains, high quality\"\n",
    "query_response = query(predictor, prompt)\n",
    "img, prmpt = query_response[\"generated_image\"], query_response[\"prompt\"] #note that output is different from inference using trained models\n",
    "display_img_and_prompt(img, prmpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae561aa-8d44-4176-a1ef-0690bdee3035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72243422-bbae-4445-b740-54a71e3af22a",
   "metadata": {},
   "source": [
    "## <a id=\"section-2\">2. Fine-tune the pre-trained model on a custom dataset<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fef5d-e1f7-47c6-94cd-1321825fb2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_version=\"*\" fetches the latest version of the model\n",
    "train_model_id, train_model_version = model_dropdown.value, \"*\"\n",
    "train_scope = \"training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561287d0-820e-413b-89b7-01e56ffd03a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "# Tested with ml.g4dn.2xlarge (16GB GPU memory) and ml.g5.2xlarge (24GB GPU memory) instances. Other instances may work as well.\n",
    "# If ml.g5.2xlarge instance type is available, please change the following instance type to speed up training.\n",
    "training_instance_type = \"ml.p3.2xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=train_scope,\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the training script. This contains all the necessary files including data processing, model training etc.\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    ")\n",
    "\n",
    "# Retrieve the pre-trained model tarball to further fine-tune\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c90a3-f1fd-464a-90bf-30935de28e66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_bucket = training_bucket\n",
    "\n",
    "s3_output_location = f\"{project_s3_path}/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e15d40-0849-44a3-a69b-a8b04d141109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\"max_steps\"] = \"300\"\n",
    "hyperparameters[\"epochs\"] = \"10\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbaae4a-c78d-487e-b10f-8c8d79a1a698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-example-{train_model_id}-transfer-learning\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "sd_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",  # Entry-point file in source_dir and present in train_source_uri.\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    "    base_job_name=training_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da93299-d520-411c-bbd5-a7054ac0c74f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Launch a SageMaker Training job by passing s3 path of the training data\n",
    "sd_estimator.fit({\"training\": dataset_s3_path}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322992e4-4b69-4667-8efc-0e765fd2e133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_instance_type = \"ml.g5.2xlarge\"\n",
    "inference_scope = \"inference\"\n",
    "\n",
    "# Retrieve the docker image for inference\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None, \n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=inference_scope,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-{train_model_id}-transfer-learning\")\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "predictor = sd_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    image_uri=deploy_image_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98296181-fc87-418c-ac51-365ad849afcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple text input\n",
    "prompt = \"AWS Lambda on a rock, in a dream landscape, cinematic composition, futuristic, in the mountains, high quality\"\n",
    "query_response = query(predictor, prompt)\n",
    "img, prmpt = parse_response(query_response)\n",
    "display_img_and_prompt(img, prmpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665235c3-31d2-49e9-82e0-627595d90b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Payload input\n",
    "prompt = \"AWS Lambda on a rock, in a dream landscape, cinematic composition, futuristic, in the mountains, high quality\"\n",
    "negative_prompt = None\n",
    "payload = {\"prompt\": prompt, \n",
    "           \"negative_prompt\": negative_prompt, \n",
    "           \"seed\": 16,\n",
    "           \"num_images_per_prompt\": 1,\n",
    "           \"num_inference_steps\": 50,\n",
    "           \"guidance_scale\": 10,\n",
    "          }\n",
    "\n",
    "query_response = query_endpoint_with_json_payload(\n",
    "    predictor, payload, \"application/json\", \"application/json\"\n",
    ")\n",
    "generated_images, prompt = parse_response_multiple_images(query_response)\n",
    "\n",
    "for img in generated_images:\n",
    "    display_img_and_prompt(img, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d688f9-b90a-4f44-9a4e-55d6c882ec99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Payload input with negative prompt\n",
    "prompt = \"AWS Lambda on a rock, in a dream landscape, cinematic composition, futuristic, in the mountains, high quality\"\n",
    "negative_prompt = \"bubble\"\n",
    "payload = {\"prompt\": prompt, \n",
    "           \"negative_prompt\": negative_prompt, \n",
    "           \"seed\": 16,\n",
    "           \"num_images_per_prompt\": 1,\n",
    "           \"num_inference_steps\": 50,\n",
    "           \"guidance_scale\": 10,\n",
    "          }\n",
    "\n",
    "query_response = query_endpoint_with_json_payload(\n",
    "    predictor, payload, \"application/json\", \"application/json\"\n",
    ")\n",
    "generated_images, prompt = parse_response_multiple_images(query_response)\n",
    "\n",
    "for img in generated_images:\n",
    "    display_img_and_prompt(img, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e67261-e17a-4a6b-8c7d-ec95afb40416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "#predictor.delete_model()\n",
    "#predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f7fd5-14e8-4d01-afac-c776836ced59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a id=\"section-3\">3. Further tuning the model with hyperparameter optimization<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3b7fe-eda5-485f-ab53-09ea10888113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter\n",
    "from sagemaker.tuner import ContinuousParameter\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "tuning_job_name = experiment_name\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(1e-6, 3e-6, \"Linear\"),\n",
    "    \"max_steps\": IntegerParameter(50, 400, \"Linear\"),\n",
    "    \"epochs\": IntegerParameter(10, 30, \"Linear\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4bfb3-7ee9-49ee-936e-291343f2faaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sd_estimator.set_hyperparameters(compute_fid=\"False\")\n",
    "\n",
    "tuner_parameters = {\n",
    "    \"estimator\": sd_estimator,\n",
    "    \"metric_definitions\": [{\"Name\": \"fid_score\", \"Regex\": \"fid_score=([-+]?\\\\d\\\\.?\\\\d*)\"},\n",
    "                          {\"Name\": \"train_avg_loss\", \"Regex\": \"train_avg_loss=([-+]?\\\\d\\\\.?\\\\d*)\"}],\n",
    "    \"objective_metric_name\": \"train_avg_loss\",\n",
    "    \"objective_type\": \"Minimize\",\n",
    "    \"hyperparameter_ranges\": hyperparameter_ranges,\n",
    "    \"max_jobs\": 10,\n",
    "    \"max_parallel_jobs\": 1,\n",
    "    \"strategy\": \"Bayesian\",\n",
    "    \"base_tuning_job_name\": {training_job_name},\n",
    "}\n",
    "\n",
    "tuner = HyperparameterTuner(**tuner_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0668bef-8b4c-40a7-864e-71535556ba1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tuner.fit(\n",
    "    {\"training\": dataset_s3_path}, \n",
    "    job_name=tuning_job_name,\n",
    "    logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9d423",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "If the tuner times out, rerun the first cell after [Deploy and test the SageMaker JumpStart model](#Section-1), uncomment the variable `tuning_job_name` and copy the tuning job name before running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe299a18-a371-462e-a3ce-9d2b36b66d07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuning_job_name = #specify tuning job name\n",
    "\n",
    "sm = boto3.client('sagemaker')\n",
    "hpo_jobs = sm.list_training_jobs_for_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuning_job_name,\n",
    "    MaxResults=100,\n",
    "    SortBy='FinalObjectiveMetricValue',\n",
    "    SortOrder='Ascending')\n",
    "\n",
    "joblist = []\n",
    "hposummaries = hpo_jobs['TrainingJobSummaries']\n",
    "\n",
    "for job in hposummaries[:]:\n",
    "    TrainingJobName=job['TrainingJobName']\n",
    "    job_descr = sm.describe_training_job(TrainingJobName=TrainingJobName)\n",
    "    metrics = {m['MetricName']:  m['Value'] for m in job_descr['FinalMetricDataList']}\n",
    "    hyperparams = job['TunedHyperParameters']\n",
    "    joblist.append({\"Training job name\": TrainingJobName, \"Metrics\": metrics, \"Hyperparameters\": hyperparams})\n",
    "print(*joblist,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa16bd4",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "Do not run the following cell if the tuner has timed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628cd656-1449-426f-9292-cc07c7723b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Run if tuner has not timed out, else use the following cell\n",
    "\n",
    "inference_instance_type = \"ml.g5.xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    image_scope=\"inference\",\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "\n",
    "endpoint_name = f\"jumpstart-FT-{tuning_job_name}\"\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "finetuned_predictor = tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    image_uri=deploy_image_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57934509",
   "metadata": {},
   "source": [
    "**Note** \n",
    "\n",
    "Uncomment and use the following cell if the tuner has timed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Uncomment and run if tuner has timed out\n",
    "# from sagemaker.estimator import Estimator\n",
    "# from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "\n",
    "# train_model_id, train_model_version = model_dropdown.value, \"*\"\n",
    "\n",
    "# inference_instance_type = \"ml.g5.xlarge\"\n",
    "\n",
    "# # Retrieve the inference docker container uri\n",
    "# deploy_image_uri = image_uris.retrieve(\n",
    "#     region=None,\n",
    "#     framework=None,  # automatically inferred from model_id\n",
    "#     image_scope=\"inference\",\n",
    "#     model_id=train_model_id,\n",
    "#     model_version=train_model_version,\n",
    "#     instance_type=inference_instance_type,\n",
    "# )\n",
    "\n",
    "# job_name = joblist[0]['Training job name']\n",
    "\n",
    "# endpoint_name = f\"jumpstart-FT-{job_name}\"\n",
    "\n",
    "# finetuned_estimator = Estimator.attach(job_name)\n",
    "# finetuned_predictor = finetuned_estimator.deploy(\n",
    "#     instance_type = inference_instance_type,\n",
    "#     initial_instance_count = 1,\n",
    "#     image_uri=deploy_image_uri,\n",
    "#     endpoint_name=endpoint_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14cf4ac-808c-41f6-9a8b-72025ba67aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"AWS Lambda on a rock, in a dream landscape, cinematic composition, futuristic, in the mountains, high quality\"\n",
    "negative_prompt = None\n",
    "payload = {\"prompt\": prompt, \n",
    "           \"negative_prompt\": negative_prompt, \n",
    "           \"seed\": 16,\n",
    "           \"num_images_per_prompt\": 1,\n",
    "           \"num_inference_steps\": 50,\n",
    "           \"guidance_scale\": 10,\n",
    "          }\n",
    "\n",
    "query_response = query_endpoint_with_json_payload(\n",
    "    finetuned_predictor, payload, \"application/json\", \"application/json\"\n",
    ")\n",
    "generated_images, prompt = parse_response_multiple_images(query_response)\n",
    "\n",
    "for img in generated_images:\n",
    "    display_img_and_prompt(img, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0070a9f-802d-4448-8291-90e70d63ba9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"AWS Lambda on a rock, in a dream landscape, cinematic composition, futuristic, in the mountains, high quality\"\n",
    "negative_prompt = \"bubble, black border\"\n",
    "payload = {\"prompt\": prompt, \n",
    "           \"negative_prompt\": negative_prompt, \n",
    "           \"seed\": 16,\n",
    "           \"num_images_per_prompt\": 1,\n",
    "           \"num_inference_steps\": 50,\n",
    "           \"guidance_scale\": 10,\n",
    "          }\n",
    "\n",
    "\n",
    "query_response = query_endpoint_with_json_payload(\n",
    "    finetuned_predictor, payload, \"application/json\", \"application/json\"\n",
    ")\n",
    "generated_images, prompt = parse_response_multiple_images(query_response)\n",
    "\n",
    "for img in generated_images:\n",
    "    display_img_and_prompt(img, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08891c01-a2bb-49c0-81d7-cb95f25fc272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Payload input with negative prompt\n",
    "prompt = \"A photo of Singapore urban park, balloon with AWS Lambda logo, realistic, cinematic, bright, 8k\"\n",
    "payload = {\"prompt\": prompt, \n",
    "           \"negative_prompt\": \"dark, cropped, clipped, deformed, duplicates\", \n",
    "           \"seed\": 7,\n",
    "           \"num_images_per_prompt\": 1,\n",
    "           \"num_inference_steps\": 75,\n",
    "           \"guidance_scale\": 15,\n",
    "          }\n",
    "\n",
    "query_response = query_endpoint_with_json_payload(\n",
    "    finetuned_predictor, payload, \"application/json\", \"application/json\"\n",
    ")\n",
    "generated_images, prompt = parse_response_multiple_images(query_response)\n",
    "\n",
    "for img in generated_images:\n",
    "    display_img_and_prompt(img, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a443e67-d019-490a-b7c1-2345fc29498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "#finetuned_predictor.delete_model()\n",
    "#finetuned_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5102bb35-e84a-48da-8788-34ec91f705b3",
   "metadata": {},
   "source": [
    "### Select a specific training job's model to deploy for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e4dd50-7dbf-4e2f-80d8-37d89aed3fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inference_instance_type = \"ml.g4dn.xlarge\"\n",
    "\n",
    "job_name = joblist[3]['Training job name']\n",
    "# job_name = #specify training job name\n",
    "\n",
    "endpoint_name = f\"jumpstart-FT-{job_name}\"\n",
    "\n",
    "attached_estimator = Estimator.attach(job_name)\n",
    "attached_predictor = attached_estimator.deploy(\n",
    "    instance_type = inference_instance_type,\n",
    "    initial_instance_count = 1,\n",
    "    image_uri=deploy_image_uri,\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cdffa1-db9d-4be1-a80c-910dc2c366b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"AWS Lambda on a rock, in a dream landscape, cinematic composition, futuristic, in the mountains, high quality\"\n",
    "negative_prompt = \"bubble, black border\"\n",
    "payload = {\"prompt\": prompt, \n",
    "           \"negative_prompt\": negative_prompt, \n",
    "           \"seed\": 16,\n",
    "           \"num_images_per_prompt\": 1,\n",
    "           \"num_inference_steps\": 50,\n",
    "           \"guidance_scale\": 10,\n",
    "          }\n",
    "\n",
    "\n",
    "query_response = query_endpoint_with_json_payload(\n",
    "    attached_predictor, payload, \"application/json\", \"application/json\"\n",
    ")\n",
    "generated_images, prompt = parse_response_multiple_images(query_response)\n",
    "\n",
    "for img in generated_images:\n",
    "    display_img_and_prompt(img, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60dcac-5afb-4dcf-935b-a464bc5a4ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Payload input with negative prompt\n",
    "prompt = \"A photo of Singapore urban park, balloon with AWS Lambda logo, realistic, cinematic, bright, 8k\"\n",
    "payload = {\"prompt\": prompt, \n",
    "           \"negative_prompt\": \"dark, cropped, clipped, deformed, duplicates\", \n",
    "           \"seed\": 7,\n",
    "           \"num_images_per_prompt\": 1,\n",
    "           \"num_inference_steps\": 75,\n",
    "           \"guidance_scale\": 15,\n",
    "          }\n",
    "\n",
    "query_response = query_endpoint_with_json_payload(\n",
    "    attached_predictor, payload, \"application/json\", \"application/json\"\n",
    ")\n",
    "generated_images, prompt = parse_response_multiple_images(query_response)\n",
    "\n",
    "for img in generated_images:\n",
    "    display_img_and_prompt(img, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0e6f9-1e6f-4466-b69d-2f7e9f02fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SageMaker endpoint\n",
    "#attached_predictor.delete_model()\n",
    "#attached_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c7c8a1-f6ba-4f27-91a9-a4dae76ac42d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <a id=\"section-4\">4. Test locally (only if using GPU-attached instance for kernel)<a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5765af0",
   "metadata": {},
   "source": [
    "Uncomment and run the following cells to test the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf39b0-9c46-45ee-a8d8-0dca0046b636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "\n",
    "# training_job_name = joblist[0]['Training job name']\n",
    "# # training_job_name = sd_estimator._current_job_name\n",
    "# # training_job_name = #specify training job name\n",
    "# training_job = sagemaker.estimator.Estimator.attach(training_job_name)\n",
    "# model_uri = training_job.model_data\n",
    "# !mkdir -p test_models\n",
    "# !aws s3 cp $model_uri ./test_models/\n",
    "# !cd test_models && tar -xzf model.tar.gz && cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab700a1-79c8-403e-9c2f-c659c895865d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install diffusers==0.10.2 transformers scipy ftfy accelerate\n",
    "# from diffusers import StableDiffusionPipeline\n",
    "# import torch\n",
    "    \n",
    "# # torch.cuda.empty_cache()\n",
    "# # torch.cuda.ipc_collect()\n",
    "\n",
    "# generator = torch.Generator(\"cuda\").manual_seed(777)\n",
    "# pipe = StableDiffusionPipeline.from_pretrained(\"./test_models/\")\n",
    "# pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa91e7-674e-4e37-96b8-5c2dc3328875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neg_prompt = \"faces, eyes, animals, men, women\"\n",
    "# neg_prompts = [neg_prompt,neg_prompt]\n",
    "# seed = 11\n",
    "# generator = torch.Generator(device=0).manual_seed(seed)\n",
    "# all_prompts = [\n",
    "#     \"AWS Lambda poster on brick wall, nail, sky, sunny day\",\n",
    "#     \"A large painting of AWS Lambda on a wall above a bed, modern house, urban, bright lighting\"\n",
    "# ]\n",
    "# images = pipe(all_prompts, negative_prompt=neg_prompts, guidance_scale= 50, height=512, width=512, num_inference_steps=75, generator=generator).images\n",
    "# image_grid(images, rows=1, cols=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fef7b5-3473-4e46-8378-2fa7076a470d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
