{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4358d166-dc16-444a-8a41-3224fa3c0b49",
   "metadata": {},
   "source": [
    "# Sagemaker JumpStart + HuggingFace Embeddings + Langchain\n",
    "\n",
    "## This is a Level 200 Instructor Led Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dad0c20-46ac-4026-8bb9-a1b51d243789",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 0 - Set Up Your Jupyter notebook\n",
    "\n",
    "### 00a. Set Kernel for your Jupyter notebook\n",
    "\n",
    "### For this Sagemaker Studio notebook, we will be using the following:\n",
    "- instance: ml.t3.medium\n",
    "- kernel: python 3\n",
    "- Data Science 3.0\n",
    "\n",
    "### Follow instructions provided in your lab to set up the Jupyter notebook kernel...\n",
    "\n",
    "***<span>Important - failure to set the right kernel will result in errors during execution of the Jupyter notebook cells</span>***\n",
    "\n",
    "### Sagemaker Studio uses Jupyter notebooks\n",
    "Jupyter notebooks use Python. Python is an interpretter language i.e. it does not need to be compiled. The Jupyter notebook has cells. Each cell can be executed independly and shares the same runtime memory, so any variables set can be used across the notebook. The format of the notebook allows for experimentation on the fly...  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be66f15-e11e-4aeb-abb1-61ae9af84f08",
   "metadata": {},
   "source": [
    "### 00b. Update SageMaker LLM Endpoint Name\n",
    "\n",
    "We will leverage the jumpstart-dft-falcon-7b-instruct-bf16 model you deployed directly using SageMaker JumpStart\n",
    "\n",
    "- jumpstart-dft-falcon-7b-instruct-bf16\n",
    "\n",
    "Update this configuration section to replace the value of 'endpoint_name' with the name of your deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71387ff-39ef-47eb-b361-b946dc2e43bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_MODEL_CONFIG_ = {\n",
    "    \n",
    "    \"jumpstart-dft-hf-llm-falcon-7b-instruct-bf16\" : {\n",
    "        \"aws_region\": \"us-west-2\",\n",
    "        \"endpoint_name\": \"jumpstart-dft-hf-llm-falcon-7b-instruct-bf16\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {
    "d564e8d2-9dcc-436a-8e8b-c0671e0b135a.png": {
     "image/png": "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"
    },
    "df8775f4-90cb-4191-826d-06f34ba8b9ed.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b42c60cc-be1a-4ea1-a02c-5efa1ae13ffc",
   "metadata": {},
   "source": [
    "## Part 1 - Set Up\n",
    "\n",
    "### 01a. Lab Overview\n",
    "\n",
    "\n",
    "## What is LangChain?\n",
    "![image.png](attachment:df8775f4-90cb-4191-826d-06f34ba8b9ed.png)![image.png](attachment:d564e8d2-9dcc-436a-8e8b-c0671e0b135a.png)\n",
    "\n",
    "LangChain is a framework for developing applications powered by language models. \n",
    "\n",
    "**LLMs are powerful by themselves. Why do we need libraries like LangChain?**\n",
    "LangChain provides a level of abstraction, making it super easy to use. LangChain's popularity has grown exponentially since it was first introduced and being an open source library, it is constantly evolving!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d2719-c536-4a32-9ad0-0f3a75c474a8",
   "metadata": {},
   "source": [
    "### 01b. Set up workshop dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc177a-0c1f-4a30-992d-965fefca0fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q pip\n",
    "!pip install --upgrade -q langchain\n",
    "!pip install -q transformers\n",
    "!pip install -q faiss-gpu\n",
    "!pip install -q bs4\n",
    "!pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474e4e8-896e-4fa1-ad82-561c7c9ad439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "print(langchain.__version__)\n",
    "# assert int(langchain.__version__.split(\".\")[-1]) >= 194"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200301e7-faed-4e60-8efc-e76dcb14f167",
   "metadata": {},
   "source": [
    "### 01c. Initialize text artifacts that we will use in this lab\n",
    "\n",
    "In this hands-on lab, we will experiment with multiple text artifacts, like text, documents, chat messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c126c-69cf-4ed3-a7be-ed2158d70094",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Schemas\n",
    "Langchain contains 4 schemas that are used for different tasks - Text, ChatMessages, Examples, Document. Here is the documentation of Schema in Langchain: https://docs.langchain.com/docs/components/schema/\n",
    "\n",
    "In this section, we will explore examples on how Text, Document and ChatMessages can be used, in the example of a virtual flower shop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e3d53e-2619-4f22-94cd-1127da1075c0",
   "metadata": {},
   "source": [
    "### Text\n",
    "Text is the most basic form when working with LLM. LLM consumes texts and output texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e058ae-046d-4746-af11-5005816cfcb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You'll be working with simple strings (that'll soon grow in complexity!)\n",
    "my_text = \"How does a lily flower look like?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00208a91-4220-4945-b433-b4cfc3cece66",
   "metadata": {},
   "source": [
    "### Documents\n",
    "Document schema are useful as it provides a method to store unstructured data, alongside with metadata associated with it. Interacting with unstructured data is widely used in LLM applications. The metadata help to give more concise information about the piece of Document, which improve efficiency in use cases like document search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70acac-8d8a-415a-be73-781cd8491603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading the required libraries\n",
    "from langchain.schema import Document\n",
    "\n",
    "page_content =\"\"\"The 'AWSome Flower' shop was founded in 2023. It was founded by three founders in Singapore. It offers a fully virtual experience.\n",
    "This flower shop opens daily from 7 am to 9 pm except on public holidays.\"\"\"\n",
    "\n",
    "# we will load the LangChain Papers as an example \n",
    "my_document = Document(page_content=page_content,\n",
    "         metadata={\n",
    "             'my_document_id' : 234234,\n",
    "             'my_document_source' : \"The LangChain Papers\",\n",
    "             'my_document_create_time' : 1680013019\n",
    "         })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a40919e-1a17-4302-b114-39b918529915",
   "metadata": {},
   "source": [
    "### Chat Messages\n",
    "Building conversational applications with LLM is common. ChatMessages help with adding in pre-configuration on the expected behaviour of the chatbot. Below shows an example on how it can be used to pre-configure a chatbot to behave as a virtual flower shop assistant. Try with different system message and see how it affects the output as we move along the lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bde540-ca58-4c06-9be7-c74804436f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cca9d2-fde8-44fe-a1ce-e0886198ceb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SystemMessage and HumanMessage are wrappers around Prompts being sent to the deployed LLM models\n",
    "# SystemMessage - Provides instruction to the LLM model on how we expect it to behave\n",
    "# HumanMessage - not required, but helps seed the LLM model on what it could expect\n",
    "[\n",
    "    SystemMessage(content=\"You are a nice AI bot that helps a user figure out what flower to buy in one short sentence\"),\n",
    "    HumanMessage(content=\"I like red, what flower should I buy?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7560f5d-d458-4227-bba6-b05a7e3ec790",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2 - Initialize the LangChain library with your deployed model endpoint\n",
    "This is how Langchain and SageMaker endpoint can be integrated. Do take note that different LLMs may require different ContentHandler definition for it to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04e739-fdf8-4555-98e9-4b43095fcb85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler, SagemakerEndpoint\n",
    "\n",
    "# These are hyper-parameters; Hyperparameters are used before inferencing a model because they have a\n",
    "# direct impact on the performance of the resulting machine learning model. \n",
    "# Hyperparameters are used before inferencing a model because they control the behavior of the model, \n",
    "# and optimize its performance for the job at hand.\n",
    "# For this workshop, hyper parameters have been identified for you...  \n",
    "parameters ={\n",
    "        \"max_new_tokens\": 600,\n",
    "        \"num_return_sequences\": 1,\n",
    "        \"top_k\": 1,\n",
    "        \"top_p\": 0.01,\n",
    "        \"do_sample\": False,\n",
    "        \"return_full_text\": False,\n",
    "        \"temperature\": 0.2\n",
    "}\n",
    "\n",
    "# A function that helps handle the JSON messages going in and out of the LLM \n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "# Passing the SagemakerEndPoint to LangChain so that it knows where to send all the inference requests\n",
    "sm_llm_falcon_instruct = SagemakerEndpoint(\n",
    "    endpoint_name=_MODEL_CONFIG_[\"jumpstart-dft-hf-llm-falcon-7b-instruct-bf16\"][\"endpoint_name\"],\n",
    "    region_name=_MODEL_CONFIG_[\"jumpstart-dft-hf-llm-falcon-7b-instruct-bf16\"][\"aws_region\"],\n",
    "    model_kwargs=parameters,\n",
    "    content_handler=content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898ee1b-fce5-4af5-93a9-94fcd7b4f509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing our Sagemaker JumpStart inference end point with a simple message to the LLM, through LangChain\n",
    "print(my_text)\n",
    "sm_llm_falcon_instruct(my_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d96b310-f31f-43f2-88e4-77e59195cfd2",
   "metadata": {},
   "source": [
    "## Part 3 - Understand text embeddings & see semantic search in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0027e-ac80-458d-8004-cb0052b60f5c",
   "metadata": {},
   "source": [
    "Here, we are loading the embedding model from hugging face via Langchain. Hugging face have many integrations with Langchain. Here is a link to the documentation to learn more: https://python.langchain.com/docs/integrations/providers/huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f66550-817a-45e2-8fa6-eb799f97c453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Huggingface Embeddings Model\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28cb3f2-f247-4cc8-a38b-29f8c0b0294f",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can also specify a specific embedding model to use. This will load the embedding model in memory. Typically, you might want to host embedding model on an endpoint or invoke it via API as a service such as Bedrock Titan Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce6852-c271-460d-a752-7dde237fb476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d12adf-eb2f-48ce-b77e-1440ec2e4bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Hi! It's time to see some beautiful sakura flowers.\"\n",
    "\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "print (f\"Your embedding is length {len(text_embedding)}\")\n",
    "print (f\"Here's a sample: {text_embedding[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4215e75-9ea0-466a-89b8-95a0d7fe8974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_1= \"Is it time for sakura viewing yet?\"\n",
    "text_2 = \"Yes, we need to go Japan now.\"\n",
    "doc_embedding = embeddings.embed_documents([text_1, text_2])\n",
    "print (f\"Your embedding is length {len(doc_embedding[0])}\")\n",
    "print (f\"Here's the first text: {doc_embedding[0][:5]}...\")\n",
    "print (f\"Here's the second text: {doc_embedding[1][:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c2d76-5094-413b-828c-c35ad1700bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_similarity_heatmap(text_labels, embeddings, rotation):\n",
    "    \"\"\"Takes sentences, embeddings and rotation as input and plot similarity heat map.\n",
    "\n",
    "    Args:\n",
    "      text_labels: a list of sentences to compute semantic textual similarity search.\n",
    "      embeddings: a list of embedding vectors, each of which corresponds to a sentence.\n",
    "      rotation: rotation used for display of the text_labels.\n",
    "    \"\"\"\n",
    "    inner_product = np.inner(embeddings, embeddings)\n",
    "    sns.set(font_scale=1.1)\n",
    "    graph = sns.heatmap(\n",
    "        inner_product,\n",
    "        xticklabels=text_labels,\n",
    "        yticklabels=text_labels,\n",
    "        vmin=np.min(inner_product),\n",
    "        vmax=1,\n",
    "        cmap=\"OrRd\",\n",
    "    )\n",
    "    graph.set_xticklabels(text_labels, rotation=rotation)\n",
    "    graph.set_title(\"Semantic Textual Similarity Between Sentences\")\n",
    "    \n",
    "sentences = [\n",
    "    # Flower order\n",
    "    \"How much is 2 bouquet of roses?\",\n",
    "    \"Can I get 5 stems of sunflowers?\",\n",
    "    \"Plese get me some roses tomorrow.\",\n",
    "    # Flower information\n",
    "    \"Jasmine is a genus of flowering plants in the family Jasminaceae.\",\n",
    "    \"Tulips is also known as Tulipa as its scientific name, as part of Liliaceae family.\",\n",
    "    # Shop\n",
    "    \"What time does your shop close?\",\n",
    "    \"How can I visit your shop?\",\n",
    "]\n",
    "\n",
    "doc_emb = embeddings.embed_documents(sentences)\n",
    "plot_similarity_heatmap(\n",
    "    sentences, normalize(\n",
    "    np.array(doc_emb), axis=1), \n",
    "    90\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c2308-7cd1-4f4e-840a-cf179c18b5e0",
   "metadata": {},
   "source": [
    "## Part 4 - Experiment with prompt and prompt templates\n",
    "Langchain offers a simple way for us to manage our prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb3b029-651c-4111-b845-0cb49794cb94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Rose is white and violets are red.\n",
    "\n",
    "What is wrong with that statement?\n",
    "\"\"\"\n",
    "\n",
    "sm_llm_falcon_instruct(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19740785-c886-4d0c-a738-a852c505c805",
   "metadata": {},
   "source": [
    "### Prompt Template\n",
    "Prompt template allow us to define a base template with variables that can be injected in during runtime, according to the user's input. You can have multiple variables per prompt. \n",
    "\n",
    "Try editing the below prompt to adapt to accepting a multi-variable input! Here is the link to the documentation for more information: https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75ed87-ac02-469b-95f8-377a3088ff78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# Notice \"flower_name\" below, that is a placeholder for another value later\n",
    "template = \"\"\"\n",
    "I want to see {flower_name} flower. Where should I go?\n",
    "\n",
    "Respond in 300 words\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"flower_name\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(flower_name='Sakura')\n",
    "\n",
    "print (f\"Final Prompt: {final_prompt}\")\n",
    "print (\"-----------\")\n",
    "print (f\"LLM Output: {sm_llm_falcon_instruct(final_prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b9dc5-0978-43ee-b5c5-b7e92750f998",
   "metadata": {},
   "source": [
    "### Prompt pipelining\n",
    "Prompt templates are designed to be re-used. There are occasions where you want to re-use them with slight modifications to the template. You can add additional string with variable to the end of a template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da908677-1386-4248-bfac-aaffbedc53be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining a prompt template from the string in previous cell\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "\n",
    "prompt = (\n",
    "    prompt_template\n",
    "    + \"and make it {tone}\"\n",
    ")\n",
    "\n",
    "print(prompt.format(flower_name=\"lily\", tone=\"funny\"))\n",
    "\n",
    "sm_llm_falcon_instruct(prompt.format(flower_name=\"lily\", tone=\"funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df0e555-7735-4885-a23e-c6ed3c59117a",
   "metadata": {},
   "source": [
    "## Part 5 - Experiment with Document Loader\n",
    "Langchain provides integrations with many third party platforms. Using document loader, you can easily connect with the data stored on the platforms. For a full list of supported platforms, refer to https://python.langchain.com/docs/integrations/document_loaders\n",
    "\n",
    "Is this lab, we will show a quick example of an integration with Hacker News."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384b35c4-739d-46ea-9cf7-5992a720e2e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HNLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95802ff9-eb53-4c7d-a01b-101de70a5711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = HNLoader(\"https://news.ycombinator.com/item?id=34422627\")\n",
    "data = loader.load()\n",
    "\n",
    "print (f\"Found {len(data)} comments\")\n",
    "print (f\"Here's a sample:\\n\\n{''.join([x.page_content[:150] for x in data[:2]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2280b-7640-48ce-81b7-13a3d58fe9db",
   "metadata": {},
   "source": [
    "### Text Splitter\n",
    "Context window limit is a common concern when working with LLMs. Text splitter provide a simple way to split documents into smaller chunks, hence fitting into the context window of the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623614db-506f-4095-a390-54e39b7273d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9aebc-1a77-423a-a7cc-046ede723349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is a long document we can split up.\n",
    "with open('Flower_Shop_FAQs.txt') as f:\n",
    "    pg_faq = f.read()\n",
    "    \n",
    "print (f\"You have {len([pg_faq])} document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc89ea8-30c2-430a-8421-0902fdc3a805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap  = 50,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([pg_faq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121f8659-1018-4fde-ad52-3cad03e64b36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774edef2-9853-4eee-9814-6cfd5076d988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (\"Preview:\")\n",
    "print (texts[0].page_content, \"\\n\")\n",
    "print (texts[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e12f3-dbde-4fed-8ecd-59282f6c7bfd",
   "metadata": {},
   "source": [
    "### Retrievers\n",
    "Retrievers are used for RAG architecture. In lab 01, we will be diving deeper into RAG. The example here features 1 of the datasource Langchain have integration with, thus making it simpler for developers. Full list of integrated retrievers: https://python.langchain.com/docs/integrations/retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8be54b-5c7f-4992-8c2c-995507634077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "loader = TextLoader('Flower_Shop_FAQs.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a08c8f-f8c3-48cf-95e0-f25011a3e8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Get embedding engine ready\n",
    "embeddings\n",
    "\n",
    "# Embedd your texts\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ad496-28f1-4e5a-811e-2751842f23cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Init your retriever. Asking for just 1 document back\n",
    "retriever = db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3759c-1644-4764-838f-a2922cd3f3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"Which bus station is closest to your shop?\")\n",
    "\n",
    "print(\"\\n\\n\".join([x.page_content for x in docs[:2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e2251-eaaa-4f82-827a-c88879c14baf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f71671-2109-4466-b7d4-f0e5a97674ee",
   "metadata": {},
   "source": [
    "## Part 6 - Experiment with various chains from LangChain\n",
    "Chaining is one of the core feature of Langchain. It helps us to orchestrate the flow of the application, from using a template to retrieving data from various data stores, this feature is crucial for many GenAI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185f928-d359-42a1-81c8-025c0cc7cf09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881fd85-292d-4bd2-910b-a068c291cc69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_new_tokens\": 1500,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": False,\n",
    "    \"temperature\": 0.3,\n",
    "    \"seed\": 123\n",
    "}\n",
    "\n",
    "sm_llm_falcon_instruct.model_kwargs = parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3079d7c-852a-44f6-b272-54b736210a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Your job is to mention a flower which has a certain color as requested. Answer with 1 word of the flower name only.\n",
    "\n",
    "COLOR: {color}\n",
    "\n",
    "YOUR RESPONSE:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"color\"], template=template)\n",
    "\n",
    "# Holds my 'color' chain\n",
    "color_chain = LLMChain(llm=sm_llm_falcon_instruct, prompt=prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834731f6-cf9f-44c0-8cb7-b21b39a66980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Given a flower name, create 4 lines poem about that flower.\n",
    "FLOWER NAME: {flower_name}\n",
    "\n",
    "YOUR RESPONSE:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"flower_name\"], template=template)\n",
    "\n",
    "# Holds my 'poem' chain\n",
    "poem_chain = LLMChain(llm=sm_llm_falcon_instruct, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ebc51d-d664-4b69-bfb3-516561908ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chaining the chains up sequentially\n",
    "overall_chain = SimpleSequentialChain(chains=[color_chain, poem_chain], verbose=True)\n",
    "review = overall_chain.run(\"Red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9bc21d-71b7-48a8-9895-1914c42c9199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review = overall_chain.run(\"Purple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca9b01-74a0-48e2-b3cd-c7b44f0ee757",
   "metadata": {},
   "source": [
    "### Summarization Chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96464c12-e971-4419-9502-2e3731a0a6c6",
   "metadata": {},
   "source": [
    "Let's try to build a summarization chain. Given an article, the chain is supposed to summarized each chunk of the content, and do final summarization of the chunk summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b2812-938c-4e9b-a502-69ad9d075bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader('Flower_Shop_FAQs.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=5)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73fde4d-faab-46a6-93be-5d7172cd2646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 100,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": False,\n",
    "    \"temperature\": 0.1,\n",
    "}\n",
    "\n",
    "sm_llm_falcon_instruct.model_kwargs = parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7bcec6-1d2e-4791-b00a-c3a8fbafe695",
   "metadata": {},
   "source": [
    "Let's see what is inside the article (file) that we want the chain to summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e36666-4efe-4b15-a30f-18c7fa8c71d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize Flower_Shop_FAQs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5076a435-b07e-473f-b0ce-7296da571502",
   "metadata": {},
   "source": [
    "Now let's run the summarization chain. Langchain have a few in-built summarization techniques defined by 'chain_type'. Try switching between the 3 summarization techniques and see if it yields different accuracy! (stuff, map-reduce, refine) Read this article for explanation on the different strategies https://python.langchain.com/docs/use_cases/summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a3723-72e1-484f-a02e-c7905e5a1386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# There is a lot of complexity hidden in this one line of code that is triggering chain_type=\"map_reduce\" \n",
    "# Map Reduce applies an initial prompt to each chunk of data. \n",
    "# This is then passed through the language model to generate multiple responses. \n",
    "# Another prompt is created to combine all of the initial outputs into one. \n",
    "# This technique requires more than one call to the LLM.\n",
    "chain = load_summarize_chain(sm_llm_falcon_instruct, chain_type=\"map_reduce\", verbose=True)\n",
    "chain.run(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc069a5-8b03-4af1-b3a5-13768e11cc92",
   "metadata": {},
   "source": [
    "### Chat\n",
    "Let's see how quickly we can create a chat feature with memory using Conversation Chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c48d53-cb32-47d9-9936-eb04e5682d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    human_prefix=\"Human\",\n",
    "    ai_prefix=\"AI\"\n",
    ")\n",
    "memory.chat_memory.add_user_message(\"I need to send flowers to my mother for the mother's day coming in a week. Please suggest what flower I should buy. \\n\\n\")\n",
    "memory.chat_memory.add_ai_message(\"Carnations is our top one, but we have no stock. What about Lilies?\\n\\n\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3c14f-ca75-4407-95a6-484e020e9aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": False,\n",
    "    \"temperature\": 0.7,\n",
    "    \"stop\": [\"\\n\\n\"]\n",
    "}\n",
    "\n",
    "sm_llm_falcon_instruct.model_kwargs = parameters\n",
    "\n",
    "# Exercise: How can we add in system prompt for our chatbot to behave in a specific way?\n",
    "\n",
    "prompt = PromptTemplate(template=\"\"\"\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\", input_variables=[\"history\", \"input\"])\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=sm_llm_falcon_instruct, \n",
    "    verbose=True, \n",
    "    memory=memory, \n",
    "    prompt = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94696638-3b1a-4471-8ab3-1ec8917171c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversation.run(\"Hmmm, what is another alternative?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f6f9c0-72fe-4616-a8c5-2de2885d3586",
   "metadata": {},
   "source": [
    "## Experimenting with Agents\n",
    "Langchain have agents implementations that we can simply use right out of the box. In this section, we will see how we can quickly define a few tools, and combine it with Langchain agent's default implementation. In lab 02, we will see how we can create our own custom agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad38af5-6b05-4e55-9a3b-840c84cfc827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.utilities import PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run(\"print(17*2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db5247-1d51-4968-a587-684c09234bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install wikipedia\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "wikipedia = WikipediaAPIWrapper(doc_content_chars_max=100)\n",
    "wikipedia.run('Sunflower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed93b2e-ed43-4cac-bb53-093079d7647a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install duckduckgo-search\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()\n",
    "search.run(\"Current Singapore Gardens By The Bay flower exhibition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aafbb95-ab85-4000-bb2a-a89cb4000914",
   "metadata": {},
   "source": [
    "### Tools\n",
    "Here is how we can define tools. The description helps the agent to know what is the tool for, so it can choose the appropriate too. Langchain provides a list of tools out of the box, we can create our own custom tools too! Link to this section's documentation: https://python.langchain.com/docs/modules/agents/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb99fa-fee1-41fe-9311-6ad00a418a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents.tools import Tool\n",
    "tools = [Tool(\n",
    "    name='Wikipedia',\n",
    "    func= wikipedia.run,\n",
    "    description=\"Useful for when you need to find the color of a flower.\"\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89317b0-1144-4d50-a77b-ebb68b84cb49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "python_tool = Tool(\n",
    "    name = \"python repl\",\n",
    "    func=python_repl.run,\n",
    "    description=\"useful for when you need to use python to answer a question. You should input python code\"\n",
    ")\n",
    "duckduckgo_tool = Tool(\n",
    "    name='DuckDuckGo Search',\n",
    "    func= search.run,\n",
    "    description=\"Useful for when you need to do a search on the internet to find information about countries.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3ee99-041e-4bbf-befa-5b1f17c67c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tools.append(duckduckgo_tool)\n",
    "#tools.append(wikipedia_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36158a3d-5c17-42f8-b52c-35b86eabef6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "parameters = {\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": False,\n",
    "    \"temperature\": 0.7,\n",
    "    \"seed\": 123,\n",
    "    \"stop\": [\"\\n\\n\"]\n",
    "}\n",
    "\n",
    "sm_llm_falcon_instruct.model_kwargs = parameters\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\", \n",
    "    tools=tools, \n",
    "    llm=sm_llm_falcon_instruct,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f11f8ac-99a7-47f9-98ab-ea113a931bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    zero_shot_agent.run(\"What would be the color of Lavender flowers?\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363220a7-b7e8-4061-8e60-e9f680c2ac74",
   "metadata": {},
   "source": [
    "It yields error as the model might be not trained well enough to use the ReAct framework. Let's try to give it more detailed instruction and examples We will see on how to use few-shot and custom agent parser later in notebook 02, but let's try to get a glimpse on how Agent works. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0222be4-d7d6-44ef-acdb-522b5a10e406",
   "metadata": {},
   "source": [
    "## Part 7 - AWS Integrations\n",
    "We will explore what are some of the existing Langchain integrations with AWS. These integrations will help you speed up in building your GenAI applications leveraging on AWS infrastructure and services.\n",
    "\n",
    "NOTE: Since we do not have these components deployed, the code below is for reference only. It is not to be run for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce5e783-4270-4bcf-b3cb-d4ac687cc953",
   "metadata": {},
   "source": [
    "### Amazon Kendra\n",
    "Amazon Kendra is an intelligent search service provided by Amazon Web Services (AWS). It utilizes advanced natural language processing (NLP) and machine learning algorithms to enable powerful search capabilities across various data sources within an organization. Kendra is designed to help users find the information they need quickly and accurately, improving productivity and decision-making.\n",
    "\n",
    "With Kendra, users can search across a wide range of content types, including documents, FAQs, knowledge bases, manuals, and websites. It supports multiple languages and can understand complex queries, synonyms, and contextual meanings to provide highly relevant search results.\n",
    "\n",
    "https://python.langchain.com/docs/integrations/retrievers/amazon_kendra_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c04f7-24be-4246-ac15-3feda4043523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "\n",
    "retriever = AmazonKendraRetriever(index_id=\"c0806df7-e76b-4bce-9b5c-d5582f6b1a03\")\n",
    "try:\n",
    "    retriever.get_relevant_documents(\"what is langchain?\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3fa057-f9b5-4ac7-a064-f0642cbb879d",
   "metadata": {},
   "source": [
    "### AWS Lambda\n",
    "WS Lambda is a serverless computing service provided by Amazon Web Services (AWS), designed to allow developers to build and run applications and services without the need for provisioning or managing servers. This serverless architecture enables you to focus on writing and deploying code, while AWS automatically takes care of scaling, patching, and managing the infrastructure required to run your applications.\n",
    "\n",
    "https://python.langchain.com/docs/integrations/tools/awslambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91800c6c-dde3-459f-9825-2d46646b3e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "\n",
    "llm = sm_llm_falcon_instruct\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"awslambda\"],\n",
    "    awslambda_tool_name=\"email-sender\",\n",
    "    awslambda_tool_description=\"sends an email with the specified content to test@testing123.com\",\n",
    "    function_name=\"testFunction1\",\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "try:\n",
    "    agent.run(\"Send an email to test@testing123.com saying hello world.\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28938d1a-5778-4984-8c75-73499aa10ebd",
   "metadata": {},
   "source": [
    "### DynamoDB Chat Message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad4de9-de56-47bd-9d65-638713884c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.memory.chat_message_histories import DynamoDBChatMessageHistory\n",
    "\n",
    "history = DynamoDBChatMessageHistory(table_name=\"SessionTable\", session_id=\"0\")\n",
    "\n",
    "try:\n",
    "    history.add_user_message(\"hi!\")\n",
    "\n",
    "    history.add_ai_message(\"whats up?\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d5030b-9185-4d37-a8de-6f239628258b",
   "metadata": {},
   "source": [
    "## Part 8 - Cleanup\n",
    "\n",
    "- No code here because we will leverage the deployed Sagemaker LLM Endpoint in the next lab as well\n",
    "- If you are not planning to do the next lab, you should go back to Sagemaker Console > Inference > Endpoints and manually delete your model endpoint to avoid any charges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cfa3d-75d0-4ea4-8616-4fbc3c127cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pipreqs --force"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
